{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Patient Prediction using Neural Networks & Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be trying to predict whether a patient has diabetes using a Diabetes Health Indicators Dataset from the CDC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary         category\n",
      "HighBP                  category\n",
      "HighChol                category\n",
      "CholCheck               category\n",
      "BMI                      float64\n",
      "Smoker                  category\n",
      "Stroke                  category\n",
      "HeartDiseaseorAttack    category\n",
      "PhysActivity            category\n",
      "Fruits                  category\n",
      "Veggies                 category\n",
      "HvyAlcoholConsump       category\n",
      "AnyHealthcare           category\n",
      "NoDocbcCost             category\n",
      "GenHlth                 category\n",
      "MentHlth                 float64\n",
      "PhysHlth                 float64\n",
      "DiffWalk                category\n",
      "Sex                     category\n",
      "Age                     category\n",
      "Education               category\n",
      "Income                  category\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke  \\\n",
       "0             0.0    1.0      0.0       1.0  26.0    0.0    0.0   \n",
       "\n",
       "  HeartDiseaseorAttack PhysActivity Fruits  ... AnyHealthcare NoDocbcCost  \\\n",
       "0                  0.0          1.0    0.0  ...           1.0         0.0   \n",
       "\n",
       "  GenHlth MentHlth PhysHlth  DiffWalk  Sex  Age Education Income  \n",
       "0     3.0      5.0     30.0       0.0  1.0  4.0       6.0    8.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "cdc_data = pd.read_csv(r\"C:\\Users\\broga\\OneDrive\\Desktop\\MSBA\\Adv_ML\\Labs\\Lab_4\\diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Change columns to 'category' dtype where appropriate\n",
    "cat_columns = [\n",
    "    'Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke',\n",
    "    'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump',\n",
    "    'AnyHealthcare', 'NoDocbcCost', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income', 'GenHlth'\n",
    "]\n",
    "\n",
    "# Convert to 'category' dtype\n",
    "for column in cat_columns:\n",
    "    cdc_data[column] = cdc_data[column].astype('category')\n",
    "\n",
    "# Verifying the changes\n",
    "print(cdc_data.dtypes)\n",
    "cdc_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train preprocessed size: (56553, 63)\n",
      "X test preprocessed size: (14139, 63)\n"
     ]
    }
   ],
   "source": [
    "#Define X an y\n",
    "X = cdc_data.drop('Diabetes_binary', axis=1)\n",
    "y = cdc_data['Diabetes_binary']\n",
    "\n",
    "# Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#Define reusable Column Transformer\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"enc\", enc, make_column_selector(dtype_include=['category','object'])),\n",
    "    (\"scaler\", scaler, make_column_selector(dtype_include=np.number))\n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "#Fit transform only on training data to prevent data leakage\n",
    "X_train_preprocessed = ct.fit_transform(X_train)\n",
    "X_test_preprocessed = ct.transform(X_test)\n",
    "\n",
    "print(\"X train preprocessed size:\", X_train_preprocessed.shape)\n",
    "print(\"X test preprocessed size:\", X_test_preprocessed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDC data target variable (Diabetes_binary) has already been balanced and therefore we will not have to rebalance the data at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling with Neural Networks & XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is a relatively simple model with a sigmoid activation function in the output layer and it performs to essentiall the same result as the more complex models below with around 75% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 63)]              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                1024      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1313 (5.13 KB)\n",
      "Trainable params: 1313 (5.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7284 - val_loss: 0.5116 - val_accuracy: 0.7502\n",
      "Epoch 2/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5082 - accuracy: 0.7488 - val_loss: 0.5076 - val_accuracy: 0.7534\n",
      "Epoch 3/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5059 - accuracy: 0.7504 - val_loss: 0.5090 - val_accuracy: 0.7502\n",
      "Epoch 4/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5041 - accuracy: 0.7523 - val_loss: 0.5095 - val_accuracy: 0.7526\n",
      "Epoch 5/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5038 - accuracy: 0.7516 - val_loss: 0.5064 - val_accuracy: 0.7520\n",
      "Epoch 6/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5024 - accuracy: 0.7527 - val_loss: 0.5084 - val_accuracy: 0.7518\n",
      "Epoch 7/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5022 - accuracy: 0.7522 - val_loss: 0.5056 - val_accuracy: 0.7550\n",
      "Epoch 8/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5017 - accuracy: 0.7527 - val_loss: 0.5061 - val_accuracy: 0.7509\n",
      "Epoch 9/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5012 - accuracy: 0.7533 - val_loss: 0.5060 - val_accuracy: 0.7540\n",
      "Epoch 10/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5008 - accuracy: 0.7531 - val_loss: 0.5064 - val_accuracy: 0.7508\n",
      "Epoch 11/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.5003 - accuracy: 0.7542 - val_loss: 0.5067 - val_accuracy: 0.7526\n",
      "Epoch 12/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4997 - accuracy: 0.7533 - val_loss: 0.5063 - val_accuracy: 0.7520\n",
      "Epoch 13/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4996 - accuracy: 0.7522 - val_loss: 0.5065 - val_accuracy: 0.7534\n",
      "Epoch 14/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4989 - accuracy: 0.7542 - val_loss: 0.5111 - val_accuracy: 0.7484\n",
      "Epoch 15/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4989 - accuracy: 0.7543 - val_loss: 0.5067 - val_accuracy: 0.7535\n",
      "Epoch 16/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4982 - accuracy: 0.7547 - val_loss: 0.5065 - val_accuracy: 0.7521\n",
      "Epoch 17/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4978 - accuracy: 0.7538 - val_loss: 0.5079 - val_accuracy: 0.7517\n",
      "Epoch 18/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4976 - accuracy: 0.7552 - val_loss: 0.5071 - val_accuracy: 0.7529\n",
      "Epoch 19/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4973 - accuracy: 0.7549 - val_loss: 0.5083 - val_accuracy: 0.7513\n",
      "Epoch 20/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4970 - accuracy: 0.7556 - val_loss: 0.5071 - val_accuracy: 0.7520\n",
      "Epoch 21/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7550 - val_loss: 0.5077 - val_accuracy: 0.7510\n",
      "Epoch 22/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4965 - accuracy: 0.7549 - val_loss: 0.5076 - val_accuracy: 0.7518\n",
      "Epoch 23/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4963 - accuracy: 0.7556 - val_loss: 0.5070 - val_accuracy: 0.7512\n",
      "Epoch 24/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4956 - accuracy: 0.7563 - val_loss: 0.5075 - val_accuracy: 0.7504\n",
      "Epoch 25/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4947 - accuracy: 0.7562 - val_loss: 0.5095 - val_accuracy: 0.7501\n",
      "Epoch 26/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4955 - accuracy: 0.7560 - val_loss: 0.5095 - val_accuracy: 0.7506\n",
      "Epoch 27/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4945 - accuracy: 0.7554 - val_loss: 0.5085 - val_accuracy: 0.7521\n",
      "Epoch 28/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4946 - accuracy: 0.7569 - val_loss: 0.5098 - val_accuracy: 0.7479\n",
      "Epoch 29/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4942 - accuracy: 0.7566 - val_loss: 0.5123 - val_accuracy: 0.7486\n",
      "Epoch 30/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4938 - accuracy: 0.7568 - val_loss: 0.5091 - val_accuracy: 0.7507\n",
      "Epoch 31/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4936 - accuracy: 0.7567 - val_loss: 0.5099 - val_accuracy: 0.7487\n",
      "Epoch 32/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4934 - accuracy: 0.7576 - val_loss: 0.5087 - val_accuracy: 0.7502\n",
      "Epoch 33/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4935 - accuracy: 0.7576 - val_loss: 0.5088 - val_accuracy: 0.7498\n",
      "Epoch 34/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4929 - accuracy: 0.7576 - val_loss: 0.5095 - val_accuracy: 0.7501\n",
      "Epoch 35/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4930 - accuracy: 0.7589 - val_loss: 0.5118 - val_accuracy: 0.7479\n",
      "Epoch 36/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4928 - accuracy: 0.7580 - val_loss: 0.5109 - val_accuracy: 0.7493\n",
      "Epoch 37/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7587 - val_loss: 0.5109 - val_accuracy: 0.7505\n",
      "Epoch 38/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7591 - val_loss: 0.5109 - val_accuracy: 0.7471\n",
      "Epoch 39/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7588 - val_loss: 0.5098 - val_accuracy: 0.7493\n",
      "Epoch 40/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.7596 - val_loss: 0.5100 - val_accuracy: 0.7485\n",
      "Epoch 41/50\n",
      "707/707 [==============================] - 2s 2ms/step - loss: 0.4916 - accuracy: 0.7589 - val_loss: 0.5109 - val_accuracy: 0.7485\n",
      "Epoch 42/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.7591 - val_loss: 0.5100 - val_accuracy: 0.7474\n",
      "Epoch 43/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.7584 - val_loss: 0.5098 - val_accuracy: 0.7492\n",
      "Epoch 44/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7591 - val_loss: 0.5103 - val_accuracy: 0.7478\n",
      "Epoch 45/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7590 - val_loss: 0.5115 - val_accuracy: 0.7477\n",
      "Epoch 46/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7592 - val_loss: 0.5128 - val_accuracy: 0.7460\n",
      "Epoch 47/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7581 - val_loss: 0.5113 - val_accuracy: 0.7470\n",
      "Epoch 48/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7596 - val_loss: 0.5119 - val_accuracy: 0.7491\n",
      "Epoch 49/50\n",
      "707/707 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7597 - val_loss: 0.5124 - val_accuracy: 0.7478\n",
      "Epoch 50/50\n",
      "707/707 [==============================] - 1s 1ms/step - loss: 0.4905 - accuracy: 0.7596 - val_loss: 0.5117 - val_accuracy: 0.7469\n",
      "442/442 [==============================] - 0s 818us/step\n",
      "Accuracy: 0.7524577410000707\n",
      "Precision: 0.7259106174115215\n",
      "Recall: 0.8030865961703344\n",
      "F1 Score: 0.7625508819538671\n",
      "Confusion Matrix:\n",
      " [[5019 2122]\n",
      " [1378 5620]]\n"
     ]
    }
   ],
   "source": [
    "# Model Definition \n",
    "inputs = keras.Input(shape=(X_train_preprocessed.shape[1],))\n",
    "x = layers.Dense(16, activation='relu')(inputs)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model1 = keras.Model(inputs=inputs, outputs=outputs, name=\"model_1\")\n",
    "\n",
    "# Compilation\n",
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "# Fit the model\n",
    "history1 = model1.fit(X_train_preprocessed, y_train, batch_size=64, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model using the encoded labels\n",
    "y_pred_proba = model1.predict(X_test_preprocessed)\n",
    "y_pred1 = (y_pred_proba > 0.5).astype(int)  \n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred1)\n",
    "precision = precision_score(y_test, y_pred1)\n",
    "recall = recall_score(y_test, y_pred1)\n",
    "f1 = f1_score(y_test, y_pred1)\n",
    "conf_mat = confusion_matrix(y_test, y_pred1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 was similar to Model 1 although I made it more complicated and it had very similar performance. It is interesting to not that I included more neurons, batch normalization, and the dropout method and am unable to increase the accuracy past 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 63)]              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                4096      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8833 (34.50 KB)\n",
      "Trainable params: 8577 (33.50 KB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1414/1414 [==============================] - 4s 2ms/step - loss: 0.5975 - accuracy: 0.7034 - val_loss: 0.5133 - val_accuracy: 0.7502\n",
      "Epoch 2/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.7385 - val_loss: 0.5096 - val_accuracy: 0.7545\n",
      "Epoch 3/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5255 - accuracy: 0.7411 - val_loss: 0.5101 - val_accuracy: 0.7524\n",
      "Epoch 4/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5250 - accuracy: 0.7406 - val_loss: 0.5107 - val_accuracy: 0.7513\n",
      "Epoch 5/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5236 - accuracy: 0.7438 - val_loss: 0.5065 - val_accuracy: 0.7524\n",
      "Epoch 6/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5232 - accuracy: 0.7428 - val_loss: 0.5066 - val_accuracy: 0.7511\n",
      "Epoch 7/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5216 - accuracy: 0.7439 - val_loss: 0.5057 - val_accuracy: 0.7540\n",
      "Epoch 8/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5201 - accuracy: 0.7451 - val_loss: 0.5102 - val_accuracy: 0.7521\n",
      "Epoch 9/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.7449 - val_loss: 0.5058 - val_accuracy: 0.7546\n",
      "Epoch 10/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5197 - accuracy: 0.7465 - val_loss: 0.5056 - val_accuracy: 0.7521\n",
      "Epoch 11/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5195 - accuracy: 0.7441 - val_loss: 0.5060 - val_accuracy: 0.7538\n",
      "Epoch 12/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5202 - accuracy: 0.7445 - val_loss: 0.5054 - val_accuracy: 0.7535\n",
      "Epoch 13/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5171 - accuracy: 0.7459 - val_loss: 0.5068 - val_accuracy: 0.7555\n",
      "Epoch 14/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5176 - accuracy: 0.7454 - val_loss: 0.5054 - val_accuracy: 0.7531\n",
      "Epoch 15/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5182 - accuracy: 0.7459 - val_loss: 0.5057 - val_accuracy: 0.7526\n",
      "Epoch 16/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5165 - accuracy: 0.7457 - val_loss: 0.5046 - val_accuracy: 0.7544\n",
      "Epoch 17/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5179 - accuracy: 0.7473 - val_loss: 0.5049 - val_accuracy: 0.7549\n",
      "Epoch 18/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5171 - accuracy: 0.7468 - val_loss: 0.5050 - val_accuracy: 0.7546\n",
      "Epoch 19/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5161 - accuracy: 0.7475 - val_loss: 0.5045 - val_accuracy: 0.7530\n",
      "Epoch 20/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5156 - accuracy: 0.7465 - val_loss: 0.5058 - val_accuracy: 0.7528\n",
      "Epoch 21/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5156 - accuracy: 0.7493 - val_loss: 0.5069 - val_accuracy: 0.7520\n",
      "Epoch 22/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5171 - accuracy: 0.7463 - val_loss: 0.5054 - val_accuracy: 0.7528\n",
      "Epoch 23/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5159 - accuracy: 0.7475 - val_loss: 0.5053 - val_accuracy: 0.7497\n",
      "Epoch 24/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5174 - accuracy: 0.7474 - val_loss: 0.5054 - val_accuracy: 0.7522\n",
      "Epoch 25/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5157 - accuracy: 0.7469 - val_loss: 0.5047 - val_accuracy: 0.7523\n",
      "Epoch 26/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5158 - accuracy: 0.7467 - val_loss: 0.5053 - val_accuracy: 0.7510\n",
      "Epoch 27/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5161 - accuracy: 0.7485 - val_loss: 0.5055 - val_accuracy: 0.7523\n",
      "Epoch 28/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5167 - accuracy: 0.7467 - val_loss: 0.5055 - val_accuracy: 0.7517\n",
      "Epoch 29/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5164 - accuracy: 0.7475 - val_loss: 0.5051 - val_accuracy: 0.7540\n",
      "Epoch 30/50\n",
      "1414/1414 [==============================] - 3s 2ms/step - loss: 0.5152 - accuracy: 0.7478 - val_loss: 0.5060 - val_accuracy: 0.7533\n",
      "Epoch 31/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5133 - accuracy: 0.7488 - val_loss: 0.5048 - val_accuracy: 0.7524\n",
      "Epoch 32/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.7485 - val_loss: 0.5063 - val_accuracy: 0.7512\n",
      "Epoch 33/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5141 - accuracy: 0.7471 - val_loss: 0.5064 - val_accuracy: 0.7514\n",
      "Epoch 34/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5142 - accuracy: 0.7474 - val_loss: 0.5051 - val_accuracy: 0.7517\n",
      "Epoch 35/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5134 - accuracy: 0.7479 - val_loss: 0.5065 - val_accuracy: 0.7513\n",
      "Epoch 36/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5148 - accuracy: 0.7490 - val_loss: 0.5057 - val_accuracy: 0.7525\n",
      "Epoch 37/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5109 - accuracy: 0.7490 - val_loss: 0.5056 - val_accuracy: 0.7502\n",
      "Epoch 38/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5152 - accuracy: 0.7484 - val_loss: 0.5059 - val_accuracy: 0.7537\n",
      "Epoch 39/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5149 - accuracy: 0.7483 - val_loss: 0.5056 - val_accuracy: 0.7523\n",
      "Epoch 40/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5134 - accuracy: 0.7492 - val_loss: 0.5052 - val_accuracy: 0.7510\n",
      "Epoch 41/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.7514 - val_loss: 0.5052 - val_accuracy: 0.7520\n",
      "Epoch 42/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5146 - accuracy: 0.7473 - val_loss: 0.5046 - val_accuracy: 0.7517\n",
      "Epoch 43/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.7486 - val_loss: 0.5044 - val_accuracy: 0.7527\n",
      "Epoch 44/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5113 - accuracy: 0.7487 - val_loss: 0.5055 - val_accuracy: 0.7525\n",
      "Epoch 45/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5127 - accuracy: 0.7483 - val_loss: 0.5058 - val_accuracy: 0.7529\n",
      "Epoch 46/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5135 - accuracy: 0.7501 - val_loss: 0.5055 - val_accuracy: 0.7534\n",
      "Epoch 47/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5107 - accuracy: 0.7493 - val_loss: 0.5058 - val_accuracy: 0.7518\n",
      "Epoch 48/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5130 - accuracy: 0.7486 - val_loss: 0.5055 - val_accuracy: 0.7523\n",
      "Epoch 49/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5124 - accuracy: 0.7489 - val_loss: 0.5051 - val_accuracy: 0.7530\n",
      "Epoch 50/50\n",
      "1414/1414 [==============================] - 2s 2ms/step - loss: 0.5126 - accuracy: 0.7492 - val_loss: 0.5064 - val_accuracy: 0.7528\n",
      "442/442 [==============================] - 1s 1ms/step\n",
      "Accuracy: 0.7555697008274984\n",
      "Precision: 0.725720112159062\n",
      "Recall: 0.8136610460131466\n",
      "F1 Score: 0.767178658043654\n",
      "Confusion Matrix:\n",
      " [[4989 2152]\n",
      " [1304 5694]]\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "inputs = keras.Input(shape=(X_train_preprocessed.shape[1],))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs, name=\"model_2\")\n",
    "\n",
    "# Compilation\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# Fit the model\n",
    "history2 = model2.fit(X_train_preprocessed, y_train, batch_size=32, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model using the encoded labels\n",
    "y_pred_proba = model2.predict(X_test_preprocessed)\n",
    "y_pred2 = (y_pred_proba > 0.5).astype(int) \n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred2)\n",
    "precision = precision_score(y_test, y_pred2)\n",
    "recall = recall_score(y_test, y_pred2)\n",
    "f1 = f1_score(y_test, y_pred2)\n",
    "conf_mat = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 deviates from the models above with the 'tanh' activation function within the hidden layers as well as using a 'rmsprop' optimizer instead of 'adam'. This led to the model being slightly worse, but still performing relatively close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 63)]              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2048      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3137 (12.25 KB)\n",
      "Trainable params: 3137 (12.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "663/663 [==============================] - 2s 2ms/step - loss: 0.5201 - accuracy: 0.7418 - val_loss: 0.5109 - val_accuracy: 0.7473\n",
      "Epoch 2/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7506 - val_loss: 0.5148 - val_accuracy: 0.7494\n",
      "Epoch 3/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7507 - val_loss: 0.5074 - val_accuracy: 0.7505\n",
      "Epoch 4/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7508 - val_loss: 0.5054 - val_accuracy: 0.7525\n",
      "Epoch 5/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.5038 - accuracy: 0.7517 - val_loss: 0.5085 - val_accuracy: 0.7498\n",
      "Epoch 6/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7533 - val_loss: 0.5105 - val_accuracy: 0.7477\n",
      "Epoch 7/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.5019 - accuracy: 0.7534 - val_loss: 0.5073 - val_accuracy: 0.7514\n",
      "Epoch 8/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.5010 - accuracy: 0.7539 - val_loss: 0.5071 - val_accuracy: 0.7510\n",
      "Epoch 9/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.5007 - accuracy: 0.7551 - val_loss: 0.5062 - val_accuracy: 0.7526\n",
      "Epoch 10/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7541 - val_loss: 0.5063 - val_accuracy: 0.7512\n",
      "Epoch 11/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4993 - accuracy: 0.7543 - val_loss: 0.5068 - val_accuracy: 0.7510\n",
      "Epoch 12/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4986 - accuracy: 0.7565 - val_loss: 0.5058 - val_accuracy: 0.7533\n",
      "Epoch 13/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7563 - val_loss: 0.5054 - val_accuracy: 0.7533\n",
      "Epoch 14/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4975 - accuracy: 0.7555 - val_loss: 0.5061 - val_accuracy: 0.7527\n",
      "Epoch 15/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.7569 - val_loss: 0.5064 - val_accuracy: 0.7525\n",
      "Epoch 16/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4965 - accuracy: 0.7570 - val_loss: 0.5074 - val_accuracy: 0.7517\n",
      "Epoch 17/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4960 - accuracy: 0.7575 - val_loss: 0.5083 - val_accuracy: 0.7495\n",
      "Epoch 18/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.7579 - val_loss: 0.5073 - val_accuracy: 0.7513\n",
      "Epoch 19/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4947 - accuracy: 0.7578 - val_loss: 0.5083 - val_accuracy: 0.7496\n",
      "Epoch 20/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4946 - accuracy: 0.7588 - val_loss: 0.5108 - val_accuracy: 0.7508\n",
      "Epoch 21/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4939 - accuracy: 0.7583 - val_loss: 0.5088 - val_accuracy: 0.7503\n",
      "Epoch 22/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4933 - accuracy: 0.7594 - val_loss: 0.5082 - val_accuracy: 0.7515\n",
      "Epoch 23/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4929 - accuracy: 0.7589 - val_loss: 0.5109 - val_accuracy: 0.7483\n",
      "Epoch 24/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7597 - val_loss: 0.5100 - val_accuracy: 0.7497\n",
      "Epoch 25/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4919 - accuracy: 0.7602 - val_loss: 0.5110 - val_accuracy: 0.7497\n",
      "Epoch 26/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4915 - accuracy: 0.7595 - val_loss: 0.5096 - val_accuracy: 0.7489\n",
      "Epoch 27/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4910 - accuracy: 0.7609 - val_loss: 0.5104 - val_accuracy: 0.7496\n",
      "Epoch 28/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4902 - accuracy: 0.7603 - val_loss: 0.5119 - val_accuracy: 0.7485\n",
      "Epoch 29/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4897 - accuracy: 0.7628 - val_loss: 0.5107 - val_accuracy: 0.7478\n",
      "Epoch 30/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4893 - accuracy: 0.7601 - val_loss: 0.5113 - val_accuracy: 0.7476\n",
      "Epoch 31/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.7612 - val_loss: 0.5133 - val_accuracy: 0.7490\n",
      "Epoch 32/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7635 - val_loss: 0.5132 - val_accuracy: 0.7459\n",
      "Epoch 33/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7629 - val_loss: 0.5140 - val_accuracy: 0.7484\n",
      "Epoch 34/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7637 - val_loss: 0.5165 - val_accuracy: 0.7479\n",
      "Epoch 35/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4866 - accuracy: 0.7618 - val_loss: 0.5153 - val_accuracy: 0.7478\n",
      "Epoch 36/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7645 - val_loss: 0.5144 - val_accuracy: 0.7447\n",
      "Epoch 37/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7638 - val_loss: 0.5172 - val_accuracy: 0.7450\n",
      "Epoch 38/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4848 - accuracy: 0.7646 - val_loss: 0.5158 - val_accuracy: 0.7440\n",
      "Epoch 39/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7656 - val_loss: 0.5181 - val_accuracy: 0.7421\n",
      "Epoch 40/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7660 - val_loss: 0.5163 - val_accuracy: 0.7443\n",
      "Epoch 41/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7646 - val_loss: 0.5158 - val_accuracy: 0.7443\n",
      "Epoch 42/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4824 - accuracy: 0.7666 - val_loss: 0.5182 - val_accuracy: 0.7459\n",
      "Epoch 43/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4818 - accuracy: 0.7666 - val_loss: 0.5165 - val_accuracy: 0.7444\n",
      "Epoch 44/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4816 - accuracy: 0.7655 - val_loss: 0.5181 - val_accuracy: 0.7438\n",
      "Epoch 45/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.7681 - val_loss: 0.5197 - val_accuracy: 0.7452\n",
      "Epoch 46/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4803 - accuracy: 0.7668 - val_loss: 0.5184 - val_accuracy: 0.7451\n",
      "Epoch 47/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4797 - accuracy: 0.7676 - val_loss: 0.5201 - val_accuracy: 0.7414\n",
      "Epoch 48/50\n",
      "663/663 [==============================] - 1s 2ms/step - loss: 0.4791 - accuracy: 0.7688 - val_loss: 0.5197 - val_accuracy: 0.7438\n",
      "Epoch 49/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4786 - accuracy: 0.7688 - val_loss: 0.5230 - val_accuracy: 0.7421\n",
      "Epoch 50/50\n",
      "663/663 [==============================] - 1s 1ms/step - loss: 0.4780 - accuracy: 0.7679 - val_loss: 0.5226 - val_accuracy: 0.7416\n",
      "442/442 [==============================] - 0s 874us/step\n",
      "Accuracy: 0.7474361694603578\n",
      "Precision: 0.7244269810085134\n",
      "Recall: 0.79036867676479\n",
      "F1 Score: 0.7559625503997813\n",
      "Confusion Matrix:\n",
      " [[5037 2104]\n",
      " [1467 5531]]\n"
     ]
    }
   ],
   "source": [
    "# Model Definition\n",
    "inputs = keras.Input(shape=(X_train_preprocessed.shape[1],))\n",
    "x = layers.Dense(32, activation='tanh')(inputs)\n",
    "x = layers.Dense(32, activation='tanh')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model3 = keras.Model(inputs=inputs, outputs=outputs, name=\"model_3\")\n",
    "\n",
    "# Compilation\n",
    "model3.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.summary()\n",
    "\n",
    "# Fit the model\n",
    "history3 = model3.fit(X_train_preprocessed, y_train, batch_size=64, epochs=50, validation_split=0.25)\n",
    "\n",
    "# Evaluate the model using the encoded labels\n",
    "y_pred_proba = model3.predict(X_test_preprocessed)\n",
    "y_pred3 = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred3)\n",
    "precision = precision_score(y_test, y_pred3)\n",
    "recall = recall_score(y_test, y_pred3)\n",
    "f1 = f1_score(y_test, y_pred3)\n",
    "conf_mat = confusion_matrix(y_test, y_pred3)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: XGBoost Classifer to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My best XGBoost Classifier model from a previous lab performs very similar to the Neural Network models above, although with a slightly lower accuracy. It seems that XGBoost can get close to a Neural Network given this dataset, although our first 2 models above outperform the XGBoost model in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7516552424435878\n",
      "Precision:  0.73228841479165\n",
      "Recall:  0.7933288940316137\n",
      "F1 Score:  0.7615351078685288\n"
     ]
    }
   ],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=['category','object'])), \n",
    "        (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Pipeline setup with XGBoost classifier\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),  \n",
    "    (\"xgboost\", XGBClassifier(learning_rate=0.2,max_depth=4,n_estimators=200,use_label_encoder=False, eval_metric='logloss', random_state=1))\n",
    "])\n",
    "\n",
    "# Define your scorers\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "results = cross_validate(xgb_pipeline, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy: \", np.mean(results['test_accuracy']))\n",
    "print(\"Precision: \", np.mean(results['test_precision']))\n",
    "print(\"Recall: \", np.mean(results['test_recall']))\n",
    "print(\"F1 Score: \", np.mean(results['test_f1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
