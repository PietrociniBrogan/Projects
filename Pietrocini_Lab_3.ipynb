{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "self-contained: true\n",
    "title: \"Lab 3: Naive Bayes & Neural Networks \"\n",
    "author: \"Brogan Pietrocini\"\n",
    "fontcolor: black\n",
    "backgroundcolor: whitesmoke\n",
    "format:\n",
    "    html:\n",
    "        theme: zephyr\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass  fnlwgt   education education-num  marital-status  \\\n",
       "0   39   State-gov   77516   Bachelors            13   Never-married   \n",
       "\n",
       "      occupation    relationship    race    sex  capital-gain  capital-loss  \\\n",
       "0   Adm-clerical   Not-in-family   White   Male        2174.0           0.0   \n",
       "\n",
       "   hours-per-week  native-country  income  \n",
       "0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_df = pd.read_csv(r\"C:\\Users\\broga\\OneDrive\\Desktop\\MSBA\\Adv_ML\\Labs\\Lab_3\\income_evaluation.csv\")\n",
    "income_df.columns = income_df.columns.str.strip()\n",
    "\n",
    "# Convert columns with 'object' type that represent categorical data to 'category'\n",
    "categorical_columns = ['workclass', 'education','education-num','marital-status', 'occupation', \n",
    "                       'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "\n",
    "income_df[categorical_columns] = income_df[categorical_columns].astype('category')\n",
    "\n",
    "# Convert columns with 'int64' type that represent continuous data to 'float64'\n",
    "float_columns = ['capital-gain', 'capital-loss']\n",
    "income_df[float_columns] = income_df[float_columns].astype('float64')\n",
    "income_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert categorical labels to numeric for XGBoost\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(income_df['income'])\n",
    "\n",
    "X = income_df.drop('income', axis=1)\n",
    "y = y_encoded\n",
    "\n",
    "# Split the data for Neural Network models that are more computationally expensive\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'),\n",
    "         make_column_selector(dtype_include=['category','object'])), \n",
    "        (\"standardize\", StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included the train_test_split line to handle the neural networks as GridSearchCV is computationally very expensive and takes a significant amount of time to run on my machine for neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use the Bernoulli NB method because it works well with binary variables. The class_prior parameter is included to account for the imbalance target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best parameters: {'naive_bayes__alpha': 0.5}\n",
      "Best BernoulliNB Model Accuracy: 0.7914\n",
      "Best BernoulliNB Model F1 Score: 0.6433\n",
      "Best BernoulliNB Model ROC AUC Score: 0.8794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "#class prior to deal with imbalance in data\n",
    "nb_class_prior = [0.76,0.24]\n",
    "\n",
    "nb_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),  \n",
    "    (\"naive_bayes\", BernoulliNB(class_prior=nb_class_prior))\n",
    "])\n",
    "\n",
    "# Define a simple parameter grid if you want to explore different priors or other parameters\n",
    "param_grid = {\n",
    "    \"naive_bayes__alpha\": [0.5, 1.0],  \n",
    "}\n",
    "\n",
    "# Setup GridSearchCV with metrics that are informative for imbalanced datasets\n",
    "grid_search = GridSearchCV(nb_pipeline, param_grid, cv=5, \n",
    "                           scoring={'Accuracy': make_scorer(accuracy_score), \n",
    "                                    'F1': make_scorer(f1_score),\n",
    "                                    'ROC_AUC': make_scorer(roc_auc_score, needs_threshold=True)}, \n",
    "                           refit='ROC_AUC',  \n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)  \n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Display the best scores\n",
    "best_accuracy = round(grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_], 4)\n",
    "best_f1 = round(grid_search.cv_results_['mean_test_F1'][grid_search.best_index_], 4)\n",
    "best_roc_auc = round(grid_search.cv_results_['mean_test_ROC_AUC'][grid_search.best_index_], 4)\n",
    "\n",
    "print(f\"Best BernoulliNB Model Accuracy: {best_accuracy}\")\n",
    "print(f\"Best BernoulliNB Model F1 Score: {best_f1}\")\n",
    "print(f\"Best BernoulliNB Model ROC AUC Score: {best_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a relatively simple set up and tuning process, the Naive Bayes Bernoulli method performs well and seems to be a good method for a quick and simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially compared the performance of a logistic activation function paired with an Adam solver against the same model except with a relu activation function and sgd solver. The latter model perfomed better and then I experimented more with other various parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.8105327805926609\n",
      "MLP Classifier F1 Score: 0.6131661442006269\n",
      "MLP Classifier ROC AUC Score: 0.8518633837066756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler  # Example of preprocessing\n",
    "\n",
    "# Assuming 'ct' is some kind of preprocessing suitable for classification\n",
    "mlp_pipeline1 = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"mlp_classifier\", MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "                                     activation='logistic',\n",
    "                                     solver='adam',\n",
    "                                     learning_rate='constant',\n",
    "                                     alpha=0.0001,\n",
    "                                     max_iter=1000,\n",
    "                                     n_iter_no_change=10,\n",
    "                                     batch_size=64,\n",
    "                                     random_state=1))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp_pipeline1.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred_proba = mlp_pipeline1.predict_proba(X_test)[:, 1]  # get the probability of the positive class\n",
    "y_pred = mlp_pipeline1.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Use predicted probabilities for ROC AUC\n",
    "\n",
    "# Print the results\n",
    "print(f\"MLP Classifier Accuracy: {accuracy}\")\n",
    "print(f\"MLP Classifier F1 Score: {f1}\")\n",
    "print(f\"MLP Classifier ROC AUC Score: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.8292645478274221\n",
      "MLP Classifier F1 Score: 0.616551724137931\n",
      "MLP Classifier ROC AUC Score: 0.8733773349664462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler  # Example of preprocessing\n",
    "\n",
    "# Assuming 'ct' is some kind of preprocessing suitable for classification\n",
    "mlp_pipeline2 = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"mlp_classifier\", MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "                                     activation='relu',\n",
    "                                     solver='sgd',\n",
    "                                     learning_rate='constant',\n",
    "                                     alpha=0.0001,\n",
    "                                     max_iter=1000,\n",
    "                                     n_iter_no_change=10,\n",
    "                                     batch_size=64,\n",
    "                                     random_state=1))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp_pipeline2.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred_proba = mlp_pipeline2.predict_proba(X_test)[:, 1]  # get the probability of the positive class\n",
    "y_pred = mlp_pipeline2.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Use predicted probabilities for ROC AUC\n",
    "\n",
    "# Print the results\n",
    "print(f\"MLP Classifier Accuracy: {accuracy}\")\n",
    "print(f\"MLP Classifier F1 Score: {f1}\")\n",
    "print(f\"MLP Classifier ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.8369415016121603\n",
      "MLP Classifier F1 Score: 0.6325259515570935\n",
      "MLP Classifier ROC AUC Score: 0.8821319454907113\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'ct' is some kind of preprocessing suitable for classification\n",
    "mlp_pipeline3 = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"mlp_classifier\", MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100),\n",
    "                                     activation='relu',\n",
    "                                     solver='sgd',\n",
    "                                     learning_rate='constant',\n",
    "                                     alpha=0.01,\n",
    "                                     max_iter=1000,\n",
    "                                     n_iter_no_change=10,\n",
    "                                     batch_size=264,\n",
    "                                     random_state=1))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp_pipeline3.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred_proba = mlp_pipeline3.predict_proba(X_test)[:, 1]  # get the probability of the positive class\n",
    "y_pred = mlp_pipeline3.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Use predicted probabilities for ROC AUC\n",
    "\n",
    "# Print the results\n",
    "print(f\"MLP Classifier Accuracy: {accuracy}\")\n",
    "print(f\"MLP Classifier F1 Score: {f1}\")\n",
    "print(f\"MLP Classifier ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the best performing Neural Network model I created. XGBoost was able to exceed every one of these metrics. I figure that outside the limitations of my machine and the sci-kit learn Neural Network processing capabilites I would be able to create a model that outperforms XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.8261937663135268\n",
      "MLP Classifier F1 Score: 0.6261558784676354\n",
      "MLP Classifier ROC AUC Score: 0.8762190476368882\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'ct' is some kind of preprocessing suitable for classification\n",
    "mlp_pipeline3 = Pipeline([\n",
    "    (\"preprocessing\", ct),\n",
    "    (\"mlp_classifier\", MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100, 100),\n",
    "                                     activation='relu',\n",
    "                                     solver='sgd',\n",
    "                                     learning_rate='constant',\n",
    "                                     alpha=0.001,\n",
    "                                     max_iter=1000,\n",
    "                                     n_iter_no_change=10,\n",
    "                                     batch_size=264,\n",
    "                                     random_state=1))\n",
    "])\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp_pipeline3.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred_proba = mlp_pipeline3.predict_proba(X_test)[:, 1]  # get the probability of the positive class\n",
    "y_pred = mlp_pipeline3.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # Use predicted probabilities for ROC AUC\n",
    "\n",
    "# Print the results\n",
    "print(f\"MLP Classifier Accuracy: {accuracy}\")\n",
    "print(f\"MLP Classifier F1 Score: {f1}\")\n",
    "print(f\"MLP Classifier ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# # Preprocessing step, assuming 'ct' is some pre-defined preprocessing\n",
    "# mlp_pipeline = Pipeline([\n",
    "#     (\"preprocessing\", ct),\n",
    "#     (\"mlp_regression\", MLPRegressor(random_state=1,batch_size=64))\n",
    "# ])\n",
    "\n",
    "# # Parameter grid for MLP\n",
    "# param_grid = {\n",
    "#     \"mlp_regression__hidden_layer_sizes\": [(100,)],\n",
    "#     \"mlp_regression__activation\": ['relu'],\n",
    "#     \"mlp_regression__solver\": ['adam'],\n",
    "#     \"mlp_regression__alpha\": [0.0001],\n",
    "#     \"mlp_regression__learning_rate\": ['constant'],\n",
    "#     \"mlp_regression__learning_rate_init\": [0.5]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(mlp_pipeline, param_grid, cv=5, scoring=['neg_mean_absolute_error', 'r2'], refit='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# # Convert the negative MAE to positive MAE and display the best R^2 score\n",
    "# best_mlp_mae = round(-grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_], 4)\n",
    "# best_mlp_r2 = round(grid_search.cv_results_['mean_test_r2'][grid_search.best_index_], 4)\n",
    "\n",
    "# print(f\"Best MLP Model MAE: {best_mlp_mae}\")\n",
    "# print(f\"Best MLP Model R^2: {best_mlp_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above would have been the template used to perform GridSearchCV for proper cross validation although the computation time was too intense for my specific machine and it was taking a significant amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for the imbalanced target class, I included the scale_pos_weight parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'xgboost__learning_rate': 0.2, 'xgboost__max_depth': 4, 'xgboost__n_estimators': 200}\n",
      "Best XGBoost Model Accuracy: 0.8361\n",
      "Best XGBoost Model F1 Score: 0.7164\n",
      "Best XGBoost Model ROC AUC Score: 0.9287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_scale_pos_weight = sum(y == 0) / sum(y == 1)\n",
    "\n",
    "# Pipeline setup with XGBoost classifier\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"preprocessing\", ct),  \n",
    "    (\"xgboost\", XGBClassifier(use_label_encoder=False, eval_metric='logloss',scale_pos_weight = xgb_scale_pos_weight, random_state=1))\n",
    "])\n",
    "\n",
    "# Define a simple parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    \"xgboost__max_depth\": [4,6,8],  \n",
    "    \"xgboost__learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"xgboost__n_estimators\": [100,150,200]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV with metrics that are informative for imbalanced datasets\n",
    "grid_search = GridSearchCV(xgb_pipeline, param_grid, cv=5, \n",
    "                           scoring={'Accuracy': make_scorer(accuracy_score), \n",
    "                                    'F1': make_scorer(f1_score),\n",
    "                                    'ROC_AUC': make_scorer(roc_auc_score, needs_threshold=True)}, \n",
    "                           refit='ROC_AUC',  \n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Display the best scores\n",
    "best_accuracy = round(grid_search.cv_results_['mean_test_Accuracy'][grid_search.best_index_], 4)\n",
    "best_f1 = round(grid_search.cv_results_['mean_test_F1'][grid_search.best_index_], 4)\n",
    "best_roc_auc = round(grid_search.cv_results_['mean_test_ROC_AUC'][grid_search.best_index_], 4)\n",
    "\n",
    "print(f\"Best XGBoost Model Accuracy: {best_accuracy}\")\n",
    "print(f\"Best XGBoost Model F1 Score: {best_f1}\")\n",
    "print(f\"Best XGBoost Model ROC AUC Score: {best_roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to (what I believe) the local computational limitations for tuning the Neural Network, my XGBoost model outperformed every other model which is common among kaggle-esque style predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
